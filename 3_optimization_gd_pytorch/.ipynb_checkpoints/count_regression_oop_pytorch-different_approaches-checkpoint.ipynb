{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:21:21.440191Z",
     "start_time": "2019-08-06T09:21:21.266184Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# create dummy data for training\n",
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Approach\n",
    "\n",
    "\n",
    "\n",
    "### Poisson Regression ?\n",
    "The question is whether the logarithm of the weekly disease counts can be modeled as a linear combination of the weekly keyword counts.\n",
    "It is unnatural to assume that the logarithm one count variable could be modeled as a linear combination of other counts, thus Poisson Regression is not the approach to take here.\n",
    "\n",
    "### Black-Box Approach ? \n",
    "Nevertheless, the black-box model should always be possible to be implemented due to the universal approximation theorem.\n",
    "\n",
    "We are going to use LSTM Neural network with categorical cross entropy VS ....\n",
    "\n",
    "To simulate the Bayesian approach :\n",
    "The fact of randomly turning neurons on and off is roughly equivalent to performing a sampling of a Bernoulli distribution, and therefore “simulates” the mechanics of a Bayesian Neural Network (where weights are distributions, and not single values). Applying dropout is a bit like if we were “sampling” from the network. And if we repeat this process several times during inference, we will get different predictions with which we can estimate a distribution and eventually, uncertainty !\n",
    "\n",
    "This paper is inspired by the Monte Carlo dropout (MC dropout) framework proposed in [13] and [22], which\n",
    "requires no change of the existing model architecture and provides uncertainty estimation almost for free. Specifically, stochastic dropouts are applied after each hidden layer, and the model output can be approximately viewed as a random sample generated from the posterior predictive distribution\n",
    "[21]. As a result, the model uncertainty can be estimated by the sample variance of the model predictions in a few\n",
    "repetitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2014-04-28 00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2014-05-05 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2014-05-12 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2014-05-19 00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2014-05-26 00:00:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0     1    2    3    4     5    6    7     8     9   \\\n",
       "277  2014-04-28 00:00:00   8.0  2.0  0.0  1.0   3.0  1.0  1.0   4.0  14.0   \n",
       "278  2014-05-05 00:00:00   6.0  0.0  3.0  3.0  17.0  0.0  1.0   4.0  23.0   \n",
       "279  2014-05-12 00:00:00   6.0  0.0  5.0  2.0  12.0  0.0  0.0   8.0  32.0   \n",
       "280  2014-05-19 00:00:00   4.0  2.0  1.0  3.0  13.0  0.0  0.0  13.0  17.0   \n",
       "281  2014-05-26 00:00:00  13.0  2.0  0.0  1.0   5.0  1.0  0.0   5.0  22.0   \n",
       "\n",
       "       10    11  12  \n",
       "277   3.0  15.0   5  \n",
       "278   1.0   6.0  12  \n",
       "279   1.0   4.0  11  \n",
       "280   2.0   6.0  10  \n",
       "281  14.0   2.0   1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from numpy import genfromtxt\n",
    "\n",
    "os.chdir(\"/media/sf_dl_projects_combined/ml_for_python_2019_/4_revision_python_programming/pytorch_problem\")\n",
    "\n",
    "train_path = os.path.abspath(\n",
    "    os.path.join(\n",
    "        \"data\",\n",
    "        'training_set.csv'\n",
    "    )\n",
    ")\n",
    "\n",
    "test_path = os.path.abspath(\n",
    "    os.path.join(  \n",
    "        \"data\",\n",
    "        'test_set.csv'\n",
    "    )\n",
    ")\n",
    "\n",
    "train = pd.read_csv(train_path,delimiter=\";\",header=None)\n",
    "test = pd.read_csv(test_path,delimiter=\";\",header=None)\n",
    "\n",
    "#test = genfromtxt(test_path,delimiter=\";\")\n",
    "\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-02 00:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-09 00:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-06-16 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-06-23 00:00:00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-06-30 00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0     1    2    3    4     5    6    7     8     9    10  \\\n",
       "0  2014-06-02 00:00:00   9.0  2.0  2.0  0.0  11.0  1.0  0.0  10.0  15.0  6.0   \n",
       "1  2014-06-09 00:00:00  10.0  1.0  3.0  4.0  16.0  0.0  0.0   7.0  46.0  2.0   \n",
       "2  2014-06-16 00:00:00   6.0  2.0  0.0  1.0  10.0  0.0  0.0   8.0  20.0  1.0   \n",
       "3  2014-06-23 00:00:00  28.0  1.0  4.0  2.0   8.0  0.0  0.0   5.0  17.0  9.0   \n",
       "4  2014-06-30 00:00:00   8.0  4.0  0.0  1.0  13.0  0.0  0.0   3.0  12.0  5.0   \n",
       "\n",
       "    11  \n",
       "0  1.0  \n",
       "1  4.0  \n",
       "2  4.0  \n",
       "3  3.0  \n",
       "4  7.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_features = train.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1, forecast_horizon=1, batch_size=1):\n",
    "    batch_x, batch_y, batch_z = [], [], []\n",
    "    for i in range(0, len(dataset)-look_back-forecast_horizon-batch_size+1, batch_size):\n",
    "        for n in range(batch_size):            \n",
    "            x = dataset[['log_counts','next_is_holiday','next_bad_weather']].values[i+n:(i + n + look_back), :]\n",
    "            offset = x[0, 0]\n",
    "            y = dataset['log_counts'].values[i + n + look_back:i + n + look_back + forecast_horizon]\n",
    "            batch_x.append(np.array(x).reshape(look_back, -1))\n",
    "            batch_y.append(np.array(y))\n",
    "            batch_z.append(np.array(offset))\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        batch_z = np.array(batch_z)\n",
    "        batch_x[:, :, 0] -= batch_z.reshape(-1, 1)\n",
    "        batch_y -= batch_z.reshape(-1, 1)\n",
    "        yield batch_x, batch_y, batch_z\n",
    "        batch_x, batch_y, batch_z = [], [], []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:21:21.486185Z",
     "start_time": "2019-08-06T09:21:21.482087Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = 128\n",
    "        self.bi = 1\n",
    "        self.lstm = nn.LSTM(config.get('features'),self.hidden_size,1,dropout=0.1,bidirectional=self.bi-1,batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(self.hidden_size,self.hidden_size // 4,1,dropout=0.1,bidirectional=self.bi-1,batch_first=True)\n",
    "        self.dense = nn.Linear(self.hidden_size // 4, config.get('forecast_horizon'))\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x, batch_size=100):\n",
    "        hidden = self.init_hidden(batch_size))\n",
    "        output, _ = self.lstm(x, hidden)\n",
    "        output = F.dropout(output, p=0.5, training=True)\n",
    "        state = self.init_hidden2(batch_size)\n",
    "        output, state = self.lstm2(output, state)\n",
    "        output = F.dropout(output, p=0.5, training=True)\n",
    "        output = self.dense(state[0].squeeze(0))\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(self.bi, batch_size, self.hidden_size))\n",
    "        c0 = Variable(torch.zeros(self.bi, batch_size, self.hidden_size))\n",
    "        return h0, c0\n",
    "    \n",
    "    def init_hidden2(self, batch_size):\n",
    "        h0 = Variable(torch.zeros(self.bi, batch_size, self.hidden_size//4))\n",
    "        c0 = Variable(torch.zeros(self.bi, batch_size, self.hidden_size//4))\n",
    "        return h0, c0\n",
    "    \n",
    "    def loss(self, pred, truth):\n",
    "        return self.loss_fn(pred, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:21:21.885955Z",
     "start_time": "2019-08-06T09:21:21.883388Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "forecast_horizon = 1\n",
    "look_back = 28\n",
    "model = Model(dict(features=3, forecast_horizon=1))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "n_epochs = 5\n",
    "model.train()\n",
    "train_true_y = []\n",
    "train_pred_y = []\n",
    "for epoch in range(n_epochs):\n",
    "    ep_loss = []\n",
    "    for i, batch in enumerate(create_dataset(df[df.index<\"2018\"], look_back=look_back, forecast_horizon=1, batch_size=batch_size)):\n",
    "        print(\"[{}{}] Epoch {}: loss={:0.4f}\".format(\"-\"*(20*i//(len(df[df.index<\"2018\"])//batch_size)), \" \"*(20-(20*i//(len(df[df.index<\"2018\"])//batch_size))),epoch, np.mean(ep_loss)), end=\"\\r\")\n",
    "        try:\n",
    "            batch = [torch.Tensor(x) for x in batch]\n",
    "        except:\n",
    "            break\n",
    "        out = model.forward(batch[0].float(), batch_size)\n",
    "        loss = model.loss(out, batch[1].float())\n",
    "        if epoch == n_epochs - 1:\n",
    "            train_true_y.append((batch[1] + batch[2]).detach().numpy().reshape(-1))\n",
    "            train_pred_y.append((out + batch[2]).detach().numpy().reshape(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ep_loss.append(loss.item())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

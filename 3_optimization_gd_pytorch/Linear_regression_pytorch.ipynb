{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:21:21.440191Z",
     "start_time": "2019-08-06T09:21:21.266184Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# create dummy data for training\n",
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:21:21.486185Z",
     "start_time": "2019-08-06T09:21:21.482087Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:21:21.696864Z",
     "start_time": "2019-08-06T09:21:21.693850Z"
    }
   },
   "outputs": [],
   "source": [
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "model = linearRegression(inputDim, outputDim)\n",
    "##### For GPU #######\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:21:21.885955Z",
     "start_time": "2019-08-06T09:21:21.883388Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:21:22.120712Z",
     "start_time": "2019-08-06T09:21:22.049463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(41.1386, grad_fn=<MseLossBackward>)\n",
      "epoch 0, loss 41.13859176635742\n",
      "tensor(3.3653, grad_fn=<MseLossBackward>)\n",
      "epoch 1, loss 3.365262985229492\n",
      "tensor(0.2841, grad_fn=<MseLossBackward>)\n",
      "epoch 2, loss 0.2841035723686218\n",
      "tensor(0.0327, grad_fn=<MseLossBackward>)\n",
      "epoch 3, loss 0.03267533704638481\n",
      "tensor(0.0121, grad_fn=<MseLossBackward>)\n",
      "epoch 4, loss 0.012061134912073612\n",
      "tensor(0.0103, grad_fn=<MseLossBackward>)\n",
      "epoch 5, loss 0.010274766944348812\n",
      "tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "epoch 6, loss 0.010025296360254288\n",
      "tensor(0.0099, grad_fn=<MseLossBackward>)\n",
      "epoch 7, loss 0.009902380406856537\n",
      "tensor(0.0098, grad_fn=<MseLossBackward>)\n",
      "epoch 8, loss 0.009790865704417229\n",
      "tensor(0.0097, grad_fn=<MseLossBackward>)\n",
      "epoch 9, loss 0.009681446477770805\n",
      "tensor(0.0096, grad_fn=<MseLossBackward>)\n",
      "epoch 10, loss 0.009573332034051418\n",
      "tensor(0.0095, grad_fn=<MseLossBackward>)\n",
      "epoch 11, loss 0.00946645624935627\n",
      "tensor(0.0094, grad_fn=<MseLossBackward>)\n",
      "epoch 12, loss 0.009360743686556816\n",
      "tensor(0.0093, grad_fn=<MseLossBackward>)\n",
      "epoch 13, loss 0.009256248362362385\n",
      "tensor(0.0092, grad_fn=<MseLossBackward>)\n",
      "epoch 14, loss 0.009152856655418873\n",
      "tensor(0.0091, grad_fn=<MseLossBackward>)\n",
      "epoch 15, loss 0.009050658904016018\n",
      "tensor(0.0089, grad_fn=<MseLossBackward>)\n",
      "epoch 16, loss 0.008949598297476768\n",
      "tensor(0.0088, grad_fn=<MseLossBackward>)\n",
      "epoch 17, loss 0.008849648758769035\n",
      "tensor(0.0088, grad_fn=<MseLossBackward>)\n",
      "epoch 18, loss 0.008750837296247482\n",
      "tensor(0.0087, grad_fn=<MseLossBackward>)\n",
      "epoch 19, loss 0.008653070777654648\n",
      "tensor(0.0086, grad_fn=<MseLossBackward>)\n",
      "epoch 20, loss 0.008556456305086613\n",
      "tensor(0.0085, grad_fn=<MseLossBackward>)\n",
      "epoch 21, loss 0.008460910059511662\n",
      "tensor(0.0084, grad_fn=<MseLossBackward>)\n",
      "epoch 22, loss 0.008366404101252556\n",
      "tensor(0.0083, grad_fn=<MseLossBackward>)\n",
      "epoch 23, loss 0.008273030631244183\n",
      "tensor(0.0082, grad_fn=<MseLossBackward>)\n",
      "epoch 24, loss 0.00818063784390688\n",
      "tensor(0.0081, grad_fn=<MseLossBackward>)\n",
      "epoch 25, loss 0.008089271374046803\n",
      "tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "epoch 26, loss 0.007998955436050892\n",
      "tensor(0.0079, grad_fn=<MseLossBackward>)\n",
      "epoch 27, loss 0.007909630425274372\n",
      "tensor(0.0078, grad_fn=<MseLossBackward>)\n",
      "epoch 28, loss 0.007821300067007542\n",
      "tensor(0.0077, grad_fn=<MseLossBackward>)\n",
      "epoch 29, loss 0.007733945269137621\n",
      "tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "epoch 30, loss 0.007647610269486904\n",
      "tensor(0.0076, grad_fn=<MseLossBackward>)\n",
      "epoch 31, loss 0.007562204264104366\n",
      "tensor(0.0075, grad_fn=<MseLossBackward>)\n",
      "epoch 32, loss 0.007477781269699335\n",
      "tensor(0.0074, grad_fn=<MseLossBackward>)\n",
      "epoch 33, loss 0.007394210435450077\n",
      "tensor(0.0073, grad_fn=<MseLossBackward>)\n",
      "epoch 34, loss 0.007311683613806963\n",
      "tensor(0.0072, grad_fn=<MseLossBackward>)\n",
      "epoch 35, loss 0.007230015005916357\n",
      "tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "epoch 36, loss 0.007149295881390572\n",
      "tensor(0.0071, grad_fn=<MseLossBackward>)\n",
      "epoch 37, loss 0.007069468032568693\n",
      "tensor(0.0070, grad_fn=<MseLossBackward>)\n",
      "epoch 38, loss 0.006990512367337942\n",
      "tensor(0.0069, grad_fn=<MseLossBackward>)\n",
      "epoch 39, loss 0.006912449840456247\n",
      "tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "epoch 40, loss 0.006835250183939934\n",
      "tensor(0.0068, grad_fn=<MseLossBackward>)\n",
      "epoch 41, loss 0.006758946925401688\n",
      "tensor(0.0067, grad_fn=<MseLossBackward>)\n",
      "epoch 42, loss 0.00668345158919692\n",
      "tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "epoch 43, loss 0.006608798634260893\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "epoch 44, loss 0.006535066291689873\n",
      "tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "epoch 45, loss 0.0064620948396623135\n",
      "tensor(0.0064, grad_fn=<MseLossBackward>)\n",
      "epoch 46, loss 0.006389894988387823\n",
      "tensor(0.0063, grad_fn=<MseLossBackward>)\n",
      "epoch 47, loss 0.006318539381027222\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "epoch 48, loss 0.006248005200177431\n",
      "tensor(0.0062, grad_fn=<MseLossBackward>)\n",
      "epoch 49, loss 0.0061782593838870525\n",
      "tensor(0.0061, grad_fn=<MseLossBackward>)\n",
      "epoch 50, loss 0.006109233014285564\n",
      "tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "epoch 51, loss 0.0060409922152757645\n",
      "tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "epoch 52, loss 0.005973535589873791\n",
      "tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "epoch 53, loss 0.00590685335919261\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "epoch 54, loss 0.005840896163135767\n",
      "tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "epoch 55, loss 0.005775643512606621\n",
      "tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "epoch 56, loss 0.0057111759670078754\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "epoch 57, loss 0.005647387355566025\n",
      "tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "epoch 58, loss 0.005584291648119688\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "epoch 59, loss 0.005521970335394144\n",
      "tensor(0.0055, grad_fn=<MseLossBackward>)\n",
      "epoch 60, loss 0.0054603032767772675\n",
      "tensor(0.0054, grad_fn=<MseLossBackward>)\n",
      "epoch 61, loss 0.0053993468172848225\n",
      "tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "epoch 62, loss 0.005339014809578657\n",
      "tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "epoch 63, loss 0.005279378965497017\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "epoch 64, loss 0.005220431834459305\n",
      "tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "epoch 65, loss 0.0051621682941913605\n",
      "tensor(0.0051, grad_fn=<MseLossBackward>)\n",
      "epoch 66, loss 0.005104517564177513\n",
      "tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "epoch 67, loss 0.005047512240707874\n",
      "tensor(0.0050, grad_fn=<MseLossBackward>)\n",
      "epoch 68, loss 0.004991133231669664\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "epoch 69, loss 0.004935396835207939\n",
      "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
      "epoch 70, loss 0.004880302120000124\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "epoch 71, loss 0.004825827665627003\n",
      "tensor(0.0048, grad_fn=<MseLossBackward>)\n",
      "epoch 72, loss 0.0047719236463308334\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "epoch 73, loss 0.004718593787401915\n",
      "tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "epoch 74, loss 0.004665963351726532\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "epoch 75, loss 0.004613844677805901\n",
      "tensor(0.0046, grad_fn=<MseLossBackward>)\n",
      "epoch 76, loss 0.0045623136684298515\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "epoch 77, loss 0.004511380568146706\n",
      "tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "epoch 78, loss 0.00446101650595665\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "epoch 79, loss 0.004411150701344013\n",
      "tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "epoch 80, loss 0.0043619065545499325\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "epoch 81, loss 0.004313221201300621\n",
      "tensor(0.0043, grad_fn=<MseLossBackward>)\n",
      "epoch 82, loss 0.004265013616532087\n",
      "tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "epoch 83, loss 0.004217416048049927\n",
      "tensor(0.0042, grad_fn=<MseLossBackward>)\n",
      "epoch 84, loss 0.004170342348515987\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "epoch 85, loss 0.004123740829527378\n",
      "tensor(0.0041, grad_fn=<MseLossBackward>)\n",
      "epoch 86, loss 0.004077684134244919\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "epoch 87, loss 0.004032179247587919\n",
      "tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "epoch 88, loss 0.003987121395766735\n",
      "tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "epoch 89, loss 0.003942607901990414\n",
      "tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "epoch 90, loss 0.0038985975552350283\n",
      "tensor(0.0039, grad_fn=<MseLossBackward>)\n",
      "epoch 91, loss 0.0038550710305571556\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "epoch 92, loss 0.003812018781900406\n",
      "tensor(0.0038, grad_fn=<MseLossBackward>)\n",
      "epoch 93, loss 0.0037694412749260664\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "epoch 94, loss 0.0037273336201906204\n",
      "tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "epoch 95, loss 0.00368572142906487\n",
      "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "epoch 96, loss 0.0036445888690650463\n",
      "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "epoch 97, loss 0.0036038667894899845\n",
      "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "epoch 98, loss 0.003563638310879469\n",
      "tensor(0.0035, grad_fn=<MseLossBackward>)\n",
      "epoch 99, loss 0.0035238349810242653\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Converting inputs and labels to Variable\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T09:21:22.321914Z",
     "start_time": "2019-08-06T09:21:22.208024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.88957494]\n",
      " [ 2.9054773 ]\n",
      " [ 4.9213796 ]\n",
      " [ 6.9372816 ]\n",
      " [ 8.953184  ]\n",
      " [10.969087  ]\n",
      " [12.984988  ]\n",
      " [15.000891  ]\n",
      " [17.016792  ]\n",
      " [19.032694  ]\n",
      " [21.048597  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    if torch.cuda.is_available():\n",
    "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
    "    else:\n",
    "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "    print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
